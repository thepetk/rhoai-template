{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iu1ofeHvdNK"
      },
      "source": [
        "## Project Overview\n",
        "\n",
        "InstructLab uses a novel synthetic data-based alignment tuning method for Large Language Models (LLMs.) The \"**lab**\" in Instruct**Lab** stands for **L**arge-Scale **A**lignment for Chat**B**ots.\n",
        "\n",
        "It is an outgrowth of the paper [*LAB: Large-Scale Alignment for ChatBots*](https://arxiv.org/abs/2403.01081).\n",
        "\n",
        "### Getting Started\n",
        "\n",
        "This notebook represents one step in the InstructLab pipeline â€“ to see what else is involved, please check out https://github.com/instructlab/instructlab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWhvICmttxaS"
      },
      "source": [
        "## Overview of this Notebook\n",
        "\n",
        "This notebook is a starting point for someone to use `instructlab` through a Red Hat Openshift AI workbench terminal, taking advantage of GPU instances.\n",
        "\n",
        "The notebook focuses on the following steps:\n",
        "* [Initializing instructlab](https://github.com/instructlab/instructlab?tab=readme-ov-file#%EF%B8%8F-initialize-ilab).\n",
        "* [Downloading the model](https://github.com/instructlab/instructlab?tab=readme-ov-file#-download-the-model)\n",
        "* [Serving the model](https://github.com/instructlab/instructlab?tab=readme-ov-file#-serving-the-model)\n",
        "* [Chatting with the model](https://github.com/instructlab/instructlab?tab=readme-ov-file#-serving-the-model)\n",
        "* [Contributing a knowledge](https://github.com/instructlab/instructlab?tab=readme-ov-file#-contribute-knowledge-or-compositional-skills)\n",
        "* [Generating a synthetic dataset](https://github.com/instructlab/instructlab?tab=readme-ov-file#-generate-a-synthetic-dataset)\n",
        "* [Training the model](https://github.com/instructlab/instructlab?tab=readme-ov-file#-training-the-model)\n",
        "* [Serve the new model](https://github.com/instructlab/instructlab?tab=readme-ov-file#-serve-the-newly-trained-model)\n",
        "\n",
        "***IMPORTANT***: make sure your notebook uses GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Open a Terminal\n",
        "* TODO: Instructions on how to open a terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create instructlab dir\n",
        "* Create a new directory called `instructlab` to store the files the ilab CLI needs when running."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4TN_1gbXeQV"
      },
      "source": [
        "## Initialize InstructLab\n",
        "\n",
        "* The notebook supposes that `InstructLab` is already installed in your system.\n",
        "* If it's not, please follow these [installation notes](https://github.com/instructlab/instructlab?tab=readme-ov-file#-installing-ilab)\n",
        "* Run the following command in the terminal you've opened:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# go to the instructlab/ dir\n",
        "cd instructlab/\n",
        "\n",
        "# initialize the configuration of ilab\n",
        "ilab config init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the model\n",
        "* While on the terminal window you have already opened, run the following command to download the default model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you'd like to use a specific model, then type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "HF_TOKEN=<YOUR HUGGINGFACE TOKEN GOES HERE> ilab model download --repository=<hg-repo> --filename=<hg-model>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serve the model\n",
        "* In order to serve the model run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model serve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you want to use an alternative/specific model then run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model serve --model-path models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat with the model\n",
        "* You can chat with the model by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contribute a knowledge\n",
        "* Clone the taxonomy repo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "git clone https://github.com/instructlab/taxonomy.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* Follow the instructions from `instructlab` [taxonomy docs](https://github.com/instructlab/taxonomy/blob/main/README.md) and add the knowledge you'd like to this repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a sythetic dataset\n",
        "* To generate a synthetic dataset based on your newly added knowledge or skill set in taxonomy repository, run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab data generate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* To use a non-default model run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab data generate --model <your-model>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "* Stop any `chat` or `serve` terminals.\n",
        "* Now that you have generated a synthetic dataset you're ready to train your model by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model train --device=cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Note that this might take a while*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test & Validate the updates\n",
        "* You can test the model by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "ilab model test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Serve the new model again by running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# convert the trained model\n",
        "ilab model convert\n",
        "\n",
        "# serve again the model\n",
        "ilab model serve --model-path <new-model>\n",
        "\n",
        "# on a separate terminal\n",
        "ilab model chat -m <new-model-name>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
